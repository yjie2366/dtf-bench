#!/bin/sh

SPLIT_WRAPPER=@split_wrapper@
top_dir=@abs_top_builddir@
bin_scale="${top_dir}/bin/scale"
bin_letkf="${top_dir}/bin/letkf"
scale_nodes=scale.nodes
letkf_nodes=letkf.nodes

trap_int()
{
	trap - SIGINT
	echo "Execution of the benchmark is interrupted!"
	exit
}

append_ppn()
{
	machine_file=$1
	ppn=$2

	sed -e "s/$/:${ppn}/" -i ${machine_file}
}

trap trap_int SIGINT

for opts; do
	if [ "${opts:0:1}" != "-" ]; then
		shift; continue
	else
		opts=`echo ${opts} | tr -d -`
		shift
	fi
	case $opts in
		np)
			np=$1
			;;
		imax)
			imax=$1
			;;
		jmax)
			jmax=$1
			;;
		cycles)
			cycles=$1
			;;
		member)
			member=$1
			;;
		run)
			num_run=$1
			;;
		master)
			master=$1
			;;
		px)
			px=$1
			;;
		py)
			py=$1
			;;
		node)
			nnodes=$1
			;;
		*)
			echo "$0 [ERROR]: Invalid option -$opts"
			exit
	esac
done

if [ -z "$np" ]; then np=4; fi
if [ -z "$imax" ]; then imax=80; fi
if [ -z "$jmax" ]; then jmax=80; fi
if [ -z "$cycles" ]; then cycles=6; fi
if [ -z "$member" ]; then member=2; fi
if [ -z "$master" ]; then master=2; fi
if [ -z "$num_run" ]; then num_run=1; fi
# If number of nodes is not set, set into
# number of processes (one process per node)
if [ -z "$nnodes" ]; then nnodes=${np}; fi

SCALE_NP=$((np/member))
if [ ${master} -gt ${SCALE_NP} ];then
	master=${SCALE_NP}
fi
workgroup_size=$((SCALE_NP/master))
echo "Every ${workgroup_size} procs handled by a master process"
echo "Benchmark will run ${num_run} time(s)..."
#DEBUG
echo "imax=$imax jmax=$jmax nprocs=$np cycles=$cycles"
echo "nens=$member #run=$num_run #masters=$master"
echo "px=$px py=$py"

ppn=${PJM_PROC_BY_NODE}
if [ -n "${ppn}" ]; then
	echo "ppn=${ppn}"
else
	echo "[WARNING] Unable to retrieve ppn information"
fi

# Make up the argument list for binaries
bin_opts=(-imax=${imax} -jmax=${jmax} -member=${member} -cycles=${cycles})
if [ -n "$px" -a -n "$py" ]; then
	bin_opts+=("-px=${px}" "-py=${py}")
fi

# Setup machine files (OFP)
find `pwd` \( -name "${scale_nodes}" -o -name "${letkf_nodes}" \) -exec rm {} \+

# Fugaku does not support this environment variable (Intel MPI only)
: << COMMENT
if [ -n "${I_MPI_HYDRA_HOST_FILE}" ]; then
	cat ${I_MPI_HYDRA_HOST_FILE} | head -n ${nnodes} > ${scale_nodes}
	cat ${I_MPI_HYDRA_HOST_FILE} | tail -n ${nnodes} > ${letkf_nodes}

	append_ppn ${scale_nodes} ${ppn}
	append_ppn ${letkf_nodes} ${ppn}

	mfargs_scale="-machinefile ${scale_nodes}"
	mfargs_letkf="-machinefile ${letkf_nodes}"
else
	echo "[Warning] machine file will be ignored"
fi
COMMENT

# only report error messages by default
export DTF_VERBOSE_LEVEL=2
export DTF_GLOBAL_PATH=${top_dir}
export DTF_IGNORE_IDLE=1
export MAX_WORKGROUP_SIZE=${workgroup_size}

# Start executing benchmark binaries
for run in `seq 1 ${num_run}`; do
	if [ -n "${SPLIT_WRAPPER}" ]; then # FUGAKU
		export LD_PRELOAD=${SPLIT_WRAPPER}/libsplitworld.so
		mpiexec -n ${np} ${bin_scale} ${bin_opts[@]} :\
		       	-n ${np} ${bin_letkf} ${bin_opts[@]}
	else # OFP
		# Verify Intel MPI version because the default ver.2019.5
	        # may not work for DTF

		impi_ver=2018.0.128 # works
		#impi_ver=2018.1.163 # works
		#impi_ver=2018.2.199 # works
			
		#impi_ver=2018.3.222 # NOT work NOT stable
		#impi_ver=2019.1.144 # NOT work
		#impi_ver=2019.3.199 # NOT work

		module switch intel/${impi_ver}
		echo "Intel MPI version: $(which mpiexec | grep -oE "[0-9]+.[0-9]+.[0-9]+")"

		mpiexec -n ${np} ${mfargs_scale} ${bin_scale} ${bin_opts[@]} &
		mpiexec	-n ${np} ${mfargs_letkf} ${bin_letkf} ${bin_opts[@]}
	fi

	if [ "$?" -ne 0 ]; then
		echo "Error occurred. Please check error log!"
		break
	else
		echo "Execution succeeded!"
	fi
done

trap - SIGINT
